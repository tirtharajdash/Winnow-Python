{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Winnow2 Algorithm**\n",
    "\n",
    "*Author: Tirtharaj Dash, BITS Pilani, Goa Campus ([Homepage](https://tirtharajdash.github.io))*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use seed for reproducibility of results\n",
    "seedval = 2018\n",
    "np.random.seed(seedval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of Data ( Instances:  2434 , Features:  5000  )\n",
      "Dimension of X:  (2434, 3800)\n",
      "Dimension of y:  (2434,)\n",
      "\n",
      "Dimension of X_train:  (1947, 3800)\n",
      "Dimension of y_train:  (1947,)\n",
      "Dimension of X_val:  (487, 3800)\n",
      "Dimension of y_val:  (487,)\n",
      "\n",
      "Dimension of Data_test ( Instances:  1044 , Features:  5000  )\n",
      "Dimension of X:  (1044, 3800)\n",
      "Dimension of y:  (1044,)\n"
     ]
    }
   ],
   "source": [
    "#load the data and prepare X and y\n",
    "Data = pd.read_csv(\"train.csv\",header=None)\n",
    "print('Dimension of Data ( Instances: ',Data.shape[0],', Features: ',Data.shape[1]-1,' )')\n",
    "\n",
    "X = Data[Data.columns[0:3800]] #only for Hide-and-Seek features to match ILP results\n",
    "y = Data[Data.columns[-1]]\n",
    "print('Dimension of X: ',X.shape)\n",
    "print('Dimension of y: ',y.shape)\n",
    "\n",
    "#prepare the training and validation set from X and y\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, \n",
    "                                                  test_size=0.20, \n",
    "                                                  random_state=42,\n",
    "                                                  stratify=y,\n",
    "                                                  shuffle=True)\n",
    "\n",
    "print('\\nDimension of X_train: ',X_train.shape)\n",
    "print('Dimension of y_train: ',y_train.shape)\n",
    "print('Dimension of X_val: ',X_val.shape)\n",
    "print('Dimension of y_val: ',y_val.shape)\n",
    "\n",
    "\n",
    "#load the holdout/test set\n",
    "Data_test = pd.read_csv(\"test.csv\",header=None)\n",
    "print('\\nDimension of Data_test ( Instances: ',Data_test.shape[0],', Features: ',Data_test.shape[1]-1,' )')\n",
    "\n",
    "X_test = Data_test[Data_test.columns[0:3800]]\n",
    "y_test = Data_test[Data_test.columns[-1]]\n",
    "print('Dimension of X: ',X_test.shape)\n",
    "print('Dimension of y: ',y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to calculate accuracy\n",
    "def accuracy_score(y, y_pred):\n",
    "    \n",
    "    acc = np.mean(y == y_pred)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to calculate netsum and prediction for one instance\n",
    "def predictOne(W, X, thres):\n",
    "    \n",
    "    netsum = np.sum(W * X) #net sum\n",
    "    \n",
    "    #threshold check\n",
    "    if netsum >= thres:\n",
    "        y_hat = 1\n",
    "    else:\n",
    "        y_hat = 0\n",
    "    \n",
    "    return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to calculate netsums and predictions for all instances\n",
    "def predictAll(W, X, thres):\n",
    "    \n",
    "    NetSum = np.dot(X, W)\n",
    "    Idx = np.where(NetSum >= thres)\n",
    "    y_pred = np.zeros(X.shape[0])\n",
    "    y_pred[Idx] = 1\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to compute and print the classification summary\n",
    "def ComputePerf(W, X, y, thres, print_flag = False):\n",
    "    \n",
    "    y_pred = predictAll(W, X, thres) #compute the prediction\n",
    "    acc = accuracy_score(y, y_pred) #compute accuracy\n",
    "\n",
    "    #print the summary if printflag is True\n",
    "    if print_flag == True:\n",
    "        print('Accuracy:',acc)\n",
    "        #print(confusion_matrix(y, y_pred))\n",
    "        #print(classification_report(y, y_pred))\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to train Winnow2 using grid-search (optional)\n",
    "def TrainWinnow2(X_train, y_train, X_val, y_val, params, max_epoch=10, patience=20, verbose=False):\n",
    "    \n",
    "    n = X_train.shape[1]\n",
    "    best_perf = 0. #best val set performance so far\n",
    "    grid_space = len(params['Thres'])*len(params['Alpha']) #size of grid space\n",
    "    grid_iter = 0 #grid search iterator\n",
    "    \n",
    "    #model dictionary\n",
    "    model = {'W': [], \n",
    "             'alpha': None, \n",
    "             'thres': None, \n",
    "             'train_perf': 0.,\n",
    "             'val_perf': 0.}\n",
    "    \n",
    "    #grid search and training\n",
    "    for alpha in params['Alpha']:\n",
    "        \n",
    "        for thres in params['Thres']:\n",
    "            \n",
    "            grid_iter += 1\n",
    "        \n",
    "            print('-----------------------------------------------------------------')\n",
    "            print('Trying::\\t alpha:',alpha,'threshold:',thres,'\\t(',grid_iter,'of',grid_space,')')\n",
    "            print('-----------------------------------------------------------------')\n",
    "            \n",
    "            W = np.ones(n) #winnow2 initialisation\n",
    "            piter = 0 #patience iteration\n",
    "            modelfound = False #model found flag\n",
    "\n",
    "            for epoch in range(0,max_epoch):\n",
    "                \n",
    "                #Winnow loop (computation and update) starts\n",
    "                for i in range(1, X_train.shape[0]):\n",
    "                    y_hat = predictOne(W, X_train.iloc[i,:], thres)\n",
    "\n",
    "                    #Winnow prediction is a mismatch\n",
    "                    if y_train.iloc[i] != y_hat:\n",
    "\n",
    "                        #active attribute indices\n",
    "                        Idx = np.where(X_train.iloc[i,:] == 1)\n",
    "\n",
    "                        if y_hat == 0: \n",
    "                            W[Idx] = W[Idx] * alpha #netsum was too small (promotion step)\n",
    "\n",
    "                        else:\n",
    "                            W[Idx] = W[Idx] / alpha #netsum was too high (demotion step)\n",
    "\n",
    "                \n",
    "                #compute performance on val set\n",
    "                val_perf = ComputePerf(W, X_val, y_val, thres)\n",
    "                \n",
    "                \n",
    "                if verbose == True:\n",
    "                    train_perf  = ComputePerf(W, X_train, y_train, thres)\n",
    "                    print('[Epoch %d] train_perf: %6.4f \\tval_perf: %6.4f'%(epoch, train_perf,val_perf))\n",
    "\n",
    "                #is it a better model\n",
    "                if val_perf > best_perf:\n",
    "                    best_perf = val_perf\n",
    "                    piter = 0 #reset the patience count\n",
    "                    modelfound = True #model is found\n",
    "                    train_perf  = ComputePerf(W, X_train, y_train, thres)\n",
    "                    \n",
    "                    #update the model with new params\n",
    "                    model['W'] = W.copy() #optimal W\n",
    "                    model['alpha'] = alpha #optimal alpha\n",
    "                    model['thres'] = thres #optimal threshold\n",
    "                    model['train_perf'] = train_perf #training performance\n",
    "                    model['val_perf'] = val_perf #validation performance\n",
    "                    \n",
    "                    print('[Selected] at epoch',epoch,\n",
    "                          '\\ttrain_perf: %6.4f \\tval_perf: %6.4f'%(train_perf,val_perf))\n",
    "                    \n",
    "                else:\n",
    "                    piter = piter + 1\n",
    "                \n",
    "                if piter >= patience:\n",
    "                    print('Stopping early after epoch',(epoch+1))\n",
    "                    break\n",
    "\n",
    "            if modelfound == False:\n",
    "                print('No better model found.\\n')\n",
    "            else:\n",
    "                print('Model found and saved.\\n')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Winnow2 algorithm hyperparameters (will be decided based on a validation set)\n",
    "\n",
    "n = X_train.shape[1] #number of features\n",
    "Thres = [n, n//2] #decision threshold\n",
    "Alpha = [2, 3] #multiplicative factor for weight (promotion or demotion)\n",
    "\n",
    "#algorithm param dict\n",
    "params = {'Thres': Thres, 'Alpha': Alpha}\n",
    "\n",
    "#trainign hyperparameters\n",
    "patience = 20 #patience period for early-stopping\n",
    "verbose = False #printing verbosity during training\n",
    "max_epoch = 200 #maximum Winnow epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------\n",
      "Trying::\t alpha: 2 threshold: 3800 \t( 1 of 4 )\n",
      "-----------------------------------------------------------------\n",
      "[Selected] at epoch 0 \ttrain_perf: 0.6410 \tval_perf: 0.6386\n",
      "[Selected] at epoch 1 \ttrain_perf: 0.6441 \tval_perf: 0.6407\n",
      "[Selected] at epoch 3 \ttrain_perf: 0.6739 \tval_perf: 0.6715\n",
      "[Selected] at epoch 13 \ttrain_perf: 0.7242 \tval_perf: 0.6858\n",
      "[Selected] at epoch 16 \ttrain_perf: 0.7370 \tval_perf: 0.6920\n",
      "Stopping early after epoch 37\n",
      "Model found and saved.\n",
      "\n",
      "-----------------------------------------------------------------\n",
      "Trying::\t alpha: 2 threshold: 1900 \t( 2 of 4 )\n",
      "-----------------------------------------------------------------\n",
      "Stopping early after epoch 20\n",
      "No better model found.\n",
      "\n",
      "-----------------------------------------------------------------\n",
      "Trying::\t alpha: 3 threshold: 3800 \t( 3 of 4 )\n",
      "-----------------------------------------------------------------\n",
      "Stopping early after epoch 20\n",
      "No better model found.\n",
      "\n",
      "-----------------------------------------------------------------\n",
      "Trying::\t alpha: 3 threshold: 1900 \t( 4 of 4 )\n",
      "-----------------------------------------------------------------\n",
      "Stopping early after epoch 20\n",
      "No better model found.\n",
      "\n",
      "Best model: {'W': array([4.02571798e-233, 2.31825384e-069, 1.46936794e-039, ...,\n",
      "       1.95312500e-003, 1.15912692e-069, 1.15912692e-069]), 'alpha': 2, 'thres': 3800, 'train_perf': 0.7370313302516692, 'val_perf': 0.6919917864476386}\n"
     ]
    }
   ],
   "source": [
    "model = TrainWinnow2(X_train, y_train, \n",
    "                     X_val, y_val, \n",
    "                     params=params, \n",
    "                     max_epoch=max_epoch, \n",
    "                     patience=20, \n",
    "                     verbose=False)\n",
    "\n",
    "\n",
    "#Optimal hyperparameters for Winnow2 using validation set\n",
    "print('Best model:', model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Independent test accuracy: 0.6350574712643678\n"
     ]
    }
   ],
   "source": [
    "#test the performance of model on test set\n",
    "acc = ComputePerf(model['W'], X_test, y_test, model['thres'])\n",
    "print('Independent test accuracy:',acc)\n",
    "\n",
    "#store the results\n",
    "with open('score.txt','w') as fp:\n",
    "    fp.write(str(acc))\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the trained model (dict)\n",
    "with open('model.pkl', 'wb') as fp:\n",
    "    pickle.dump(model, fp, pickle.HIGHEST_PROTOCOL)\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load and test the saved model\n",
    "#with open('model.pkl', 'rb') as fp:\n",
    "#    savedmodel = pickle.load(fp)\n",
    "#acc = ComputePerf(savedmodel['W'], X_test, y_test, model['thres'])\n",
    "#print(acc)\n",
    "#fp.close()\n",
    "\n",
    "#print(classification_report(y_test, predictAll(W, X_test, thres)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
